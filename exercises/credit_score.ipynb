{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "This exercise is based on subset of data for the [\"Give Me Some Credit\" Kaggle competition] (https://www.kaggle.com/c/GiveMeSomeCredit), follow this link and take a look at the competition description.\n",
    "\n",
    "### Getting the data\n",
    "Dowload the data file called `credit_scoring_sample.csv` from https://github.com/Yorko/mlcourse.ai/tree/master/data\n",
    "\n",
    "\n",
    "### Data columns\n",
    "Not all of these columns are present in the sample data we user for this exercise\n",
    "\n",
    " - **SeriousDlqin2yrs** (prediction target) - Person experienced 90 days past due delinquency or worse \n",
    " - **RevolvingUtilizationOfUnsecuredLines** - Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits\n",
    " - **age** - Age of borrower in years\n",
    " - **DebtRatio** - Monthly debt payments, alimony, living costs divided by monthly gross income\n",
    " - **MonthlyIncome** - Monthly income\n",
    " - **NumberOfOpenCreditLinesAndLoans** - Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)\n",
    " - **NumberRealEstateLoansOrLines** - Number of mortgage and real estate loans including home equity lines of credit\n",
    " - **NumberOfDependents** - Number of dependents in family excluding themselves (spouse, children etc.)\n",
    " - **NumberOfTimes90DaysLate** - Number of times borrower has been 90 days or more past due.\n",
    " - **NumberOfTime60-89DaysPastDueNotWorse**\t - Number of times borrower has been 60-89 days past due but no worse in the last 2 years.\n",
    " - **NumberOfTime30-59DaysPastDueNotWorse** - Number of times borrower has been 30-59 days past due but no worse in the last 2 years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../mlcourse.ai/data/credit_scoring_sample.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>43.00000</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>0.249908</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.27182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>8158.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6666.000000</td>\n",
       "      <td>10500.00000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0       1            2  \\\n",
       "SeriousDlqin2yrs                         0.000000     0.0     0.000000   \n",
       "age                                     64.000000    58.0    41.000000   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.0     0.000000   \n",
       "DebtRatio                                0.249908  3870.0     0.456127   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.0     0.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.0     0.000000   \n",
       "MonthlyIncome                         8158.000000     NaN  6666.000000   \n",
       "NumberOfDependents                       0.000000     0.0     0.000000   \n",
       "\n",
       "                                                3          4  \n",
       "SeriousDlqin2yrs                          0.00000    1.00000  \n",
       "age                                      43.00000   49.00000  \n",
       "NumberOfTime30-59DaysPastDueNotWorse      0.00000    0.00000  \n",
       "DebtRatio                                 0.00019    0.27182  \n",
       "NumberOfTimes90DaysLate                   0.00000    0.00000  \n",
       "NumberOfTime60-89DaysPastDueNotWorse      0.00000    0.00000  \n",
       "MonthlyIncome                         10500.00000  400.00000  \n",
       "NumberOfDependents                        2.00000    0.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many columns and samples do we have in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percentage of people in this dataset had serious delinquency?\n",
    " - It's the first column `SeriousDlqin2yrs`\n",
    " - This is the column we will be trying to predict today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What accuracy score would you expect from the optimistic classifier that expects no delinquency at all?\n",
    " - This is called the Null accuracy\n",
    " - Verify that accuracy score using the `accuracy_score()` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any columns with missing (NaN) values?\n",
    "Hint: isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in all the missing values using the median value of the corresponding column\n",
    "Hint: fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define X and y to experiment with some classifiers below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using all the columns except the target to base our preidctions on\n",
    "# This is the list of the columns\n",
    "cols = df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a DecisionTreeClassifier using ALL the data and find the accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the above with different values of max_depth in the range between 2 and 15. Plot the accuracy score as a function of max_depth\n",
    "- max_depth is passed to the constructor when creating an instance of DecisionTreeClassifier. It is the maximum depth the decision tree is allowed to have and works as a way to avoid overfitting. By default, without max_depth specified DecisionTreeClassifier will split until all leaf nodes are pure (contain only samples of one class). In most cases this is sever overfitting (similar to kNN with k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = list(range(2,15))\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point we still have no idea how well our tree performs on \"out of sample\" data. Repeat the loop above, but instead of finding the training accuracy score, find the 5-fold corss_validation score on each iteration. Plot the scores as a function of max depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the plot of CV scores, what is the best value for max depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a random forest of 20 decision trees using the optimal value for max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=6)\n",
    "forest = BaggingClassifier(clf, n_estimators=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the 5-fold CV score for the `forest` classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and testing sets use 40% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit both the forest and the single tree using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the predictions according to both the tree and the forest classifiers and the corresponding accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the `confusion_matrix` for the above two predictions and the dummy\n",
    " - Where are the actual classes and where the predicted ones are?\n",
    " - Try also looking at the matrices using percentage of the samples rather than counts (divide by total number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look a the confusion matrix for the dummy prediction that predicts no delinquency at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Sensitivity, Specificity and Precision based on each of the confusion matrices\n",
    " - Use [Kavin Markham's notebook](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity is also called recall, and there is a special function sklearn.metrics.recall_score\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, ypf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity manual computation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
